{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTTAjVm0x15X"
   },
   "source": [
    "**Import necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VVwftj-t6As"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAlfb5HIx4QA"
   },
   "source": [
    "**Load the images to be aligned**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lo1bM6r3xwO_"
   },
   "outputs": [],
   "source": [
    "img1 = cv2.imread('images/exp4-2.jpg')\n",
    "img2 = cv2.imread('images/exp4-1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tISmwiP9yL2Z"
   },
   "source": [
    "**Display the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "id": "Xgpz6N3gyJNf",
    "outputId": "8745053f-cb7b-438f-f598-0e0394ac386e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img1)\n",
    "plt.title('Image 1')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img2)\n",
    "plt.title('Image 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSokM4hlyYJb"
   },
   "source": [
    "**Get human-guided control points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TuI8-_a6yPtQ"
   },
   "outputs": [],
   "source": [
    "# Get the number of control points to be selected\n",
    "num_control_points = 4\n",
    "\n",
    "# Initialize the control points list\n",
    "control_points = []\n",
    "\n",
    "# Create a window to display the image\n",
    "plt.imshow(img2)\n",
    "\n",
    "# Print the control points\n",
    "print(control_points)\n",
    "# Iterate over the number of control points\n",
    "for i in range(num_control_points):\n",
    "    # Get the mouse click coordinates\n",
    "    x, y = plt.ginput(1)[0]\n",
    "\n",
    "    # Add the control point to the list\n",
    "    control_points.append((x, y))\n",
    "\n",
    "# Display the control points on the images\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img1)\n",
    "plt.title('Image 1 with control points')\n",
    "plt.scatter(control_points[:, 0], control_points[:, 1], c='red', marker='o')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img2)\n",
    "plt.title('Image 2 with control points')\n",
    "plt.scatter(control_points[:, 0], control_points[:, 1], c='red', marker='o')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CITVTLXwym2H"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to compute the mean squared error (MSE) between two images\n",
    "def compute_mse(img1, img2):\n",
    "    mse = np.mean((img1 - img2)**2)\n",
    "    return mse\n",
    "\n",
    "# Function to warp an image to another image using a homography matrix\n",
    "def warp_image(img, H, output_shape):\n",
    "    warped_img = cv2.warpPerspective(img, H, output_shape)\n",
    "    return warped_img\n",
    "\n",
    "# Function to evaluate the efficacy of human-guided control point selection for image alignment\n",
    "def evaluate_control_point_selection(img1, img2, control_points):\n",
    "    # Compute the homography matrix\n",
    "    H = cv2.findHomography(control_points[:, ::-1], control_points[:, ::-1])[0]\n",
    "\n",
    "    # Warp the second image to the first image\n",
    "    warped_img2 = warp_image(img2, H, img1.shape)\n",
    "\n",
    "    # Compute the MSE between the aligned images\n",
    "    mse = compute_mse(img1, warped_img2)\n",
    "\n",
    "    return mse\n",
    "\n",
    "# Load the images to be aligned\n",
    "img1 = cv2.imread('images/exp4-2.jpg')\n",
    "img2 = cv2.imread('images/exp4-1.jpg')\n",
    "\n",
    "# Display the images to the user\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img1)\n",
    "plt.title('Image 1')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img2)\n",
    "plt.title('Image 2')\n",
    "plt.show()\n",
    "\n",
    "# Get human-guided control points\n",
    "num_control_points = 4\n",
    "\n",
    "# Initialize the control points list\n",
    "control_points = []\n",
    "\n",
    "# Iterate over the number of control points\n",
    "for i in range(num_control_points):\n",
    "    # Get the mouse click coordinates\n",
    "    x, y = plt.ginput(i)\n",
    "\n",
    "    # Add the control point to the list\n",
    "    control_points.append((x, y))\n",
    "\n",
    "# Display the control points on the images\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img1)\n",
    "plt.title('Image 1 with control points')\n",
    "plt.scatter(control_points[:, 0], control_points[:, 1], c='red', marker='o')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img2)\n",
    "title('Image 2 with control points')\n",
    "plt.scatter(control_points[:, 0], control_points[:, 1], c='red', marker='o')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the efficacy of human-guided control point selection\n",
    "mse = evaluate_control_point_selection(img1, img2, control_points)\n",
    "\n",
    "# Print the MSE\n",
    "print('MSE: ', mse)\n",
    "\n",
    "# Display the aligned images\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img1)\n",
    "plt.title('Image 1')\n",
    "plt.subplot(122)\n",
    "plt.imshow(warped_img2)\n",
    "plt.title('Warped Image 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load source and target images\n",
    "sourceImage = cv2.imread('images/exp4-2.jpg')\n",
    "targetImage = cv2.imread('images/exp4-1.jpg')\n",
    "\n",
    "# Display source and target images\n",
    "cv2.imshow(\"Source Image\", sourceImage)\n",
    "cv2.imshow(\"Target Image\", targetImage)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Prompt user to select control points\n",
    "sourcePoints = cv2.selectPoints(sourceImage, \"Select control points in source image\")\n",
    "targetPoints = cv2.selectPoints(targetImage, \"Select control points in target image\")\n",
    "\n",
    "# Perform image alignment\n",
    "alignedImage = cv2.warpPerspective(sourceImage, cv2.findHomography(sourcePoints, targetPoints), targetImage.shape[:2])\n",
    "\n",
    "# Display aligned image\n",
    "cv2.imshow(\"Aligned Image\", alignedImage)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Evaluate alignment quality\n",
    "alignmentQuality = cv2.matchTemplate(alignedImage, targetImage, cv2.TM_SQDIFF_NORM)\n",
    "\n",
    "# Calculate efficacy of human-guided control point selection\n",
    "efficacy = alignmentQuality / targetImage.size\n",
    "\n",
    "# Output evaluation results and efficacy metrics\n",
    "print(\"Alignment quality:\", alignmentQuality)\n",
    "print(\"Efficacy:\", efficacy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "MAX_FEATURES = 500\n",
    "GOOD_MATCH_PERCENT = 0.15\n",
    " \n",
    "def alignImages(im1, im2):\n",
    " \n",
    "  # Convert images to grayscale\n",
    "  im1Gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "  im2Gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "  # Detect ORB features and compute descriptors.\n",
    "  orb = cv2.ORB_create(MAX_FEATURES)\n",
    "  keypoints1, descriptors1 = orb.detectAndCompute(im1Gray, None)\n",
    "  keypoints2, descriptors2 = orb.detectAndCompute(im2Gray, None)\n",
    " \n",
    "  # Match features.\n",
    "  matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "  matches = matcher.match(descriptors1, descriptors2, None)\n",
    " \n",
    "  # Sort matches by score\n",
    "  matches.sort(key=lambda x: x.distance, reverse=False)\n",
    " \n",
    "  # Remove not so good matches\n",
    "  numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "  matches = matches[:numGoodMatches]\n",
    " \n",
    "  # Draw top matches\n",
    "  imMatches = cv2.drawMatches(im1, keypoints1, im2, keypoints2, matches, None)\n",
    "  cv2.imwrite(\"matches.jpg\", imMatches)\n",
    " \n",
    "  # Extract location of good matches\n",
    "  points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "  points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    " \n",
    "  for i, match in enumerate(matches):\n",
    "    points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "    points2[i, :] = keypoints2[match.trainIdx].pt\n",
    " \n",
    "  # Find homography\n",
    "  h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    " \n",
    "  # Use homography\n",
    "  height, width, channels = im2.shape\n",
    "  im1Reg = cv2.warpPerspective(im1, h, (width, height))\n",
    " \n",
    "  return im1Reg, h\n",
    " \n",
    "if __name__ == '__main__':\n",
    " \n",
    "  # Read reference image\n",
    "  refFilename = \"images/exp4-1.png\"\n",
    "  print(\"Reading reference image : \", refFilename)\n",
    "  imReference = cv2.imread(refFilename, cv2.IMREAD_COLOR)\n",
    " \n",
    "  # Read image to be aligned\n",
    "  imFilename = \"images/exp4-2.png\"\n",
    "  print(\"Reading image to align : \", imFilename);\n",
    "  im = cv2.imread(imFilename, cv2.IMREAD_COLOR)\n",
    " \n",
    "  print(\"Aligning images ...\")\n",
    "  # Registered image will be resotred in imReg.\n",
    "  # The estimated homography will be stored in h.\n",
    "  imReg, h = alignImages(im, imReference)\n",
    " \n",
    "  # Write aligned image to disk.\n",
    "  outFilename = \"aligned.jpg\"\n",
    "  print(\"Saving aligned image : \", outFilename);\n",
    "  cv2.imwrite(outFilename, imReg)\n",
    " \n",
    "  # Print estimated homography\n",
    "  print(\"Estimated homography : \\n\",  h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the images to be aligned\n",
    "im1 = cv2.imread('images/exp4-1.png')\n",
    "im2 = cv2.imread('images/exp4-2.png')\n",
    "\n",
    "# Convert images to grayscale\n",
    "im1_gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "im2_gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Display the images\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(im1_gray, cmap='gray')\n",
    "plt.title('Image 1')\n",
    "plt.subplot(122)\n",
    "plt.imshow(im2_gray, cmap='gray')\n",
    "plt.title('Image 2')\n",
    "plt.show()\n",
    "\n",
    "# Ask the user to select four corresponding points on each image\n",
    "print('Please select four corresponding points on each image by clicking on them.')\n",
    "points1 = [] # List to store the points on image 1\n",
    "points2 = [] # List to store the points on image 2\n",
    "\n",
    "# Define a callback function to record the mouse clicks\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global points1, points2\n",
    "    if event == cv2.EVENT_LBUTTONDOWN: # Left mouse button clicked\n",
    "        if len(points1) < 4: # Still need to select points on image 1\n",
    "            points1.append((x, y)) # Append the point to the list\n",
    "            cv2.circle(im1, (x, y), 5, (0, 0, 255), -1) # Draw a red circle on the image\n",
    "            cv2.imshow('Image 1', im1) # Show the updated image\n",
    "        elif len(points2) < 4: # Still need to select points on image 2\n",
    "            points2.append((x, y)) # Append the point to the list\n",
    "            cv2.circle(im2, (x, y), 5, (0, 0, 255), -1) # Draw a red circle on the image\n",
    "            cv2.imshow('Image 2', im2) # Show the updated image\n",
    "\n",
    "# Create windows to display the images\n",
    "cv2.namedWindow('Image 1')\n",
    "cv2.namedWindow('Image 2')\n",
    "\n",
    "# Set the mouse callback function for the windows\n",
    "cv2.setMouseCallback('Image 1', mouse_callback)\n",
    "cv2.setMouseCallback('Image 2', mouse_callback)\n",
    "\n",
    "# Show the images\n",
    "cv2.imshow('Image 1', im1)\n",
    "cv2.imshow('Image 2', im2)\n",
    "\n",
    "# Wait for the user to press any key\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Destroy all windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Convert the points to numpy arrays\n",
    "points1 = np.array(points1)\n",
    "points2 = np.array(points2)\n",
    "\n",
    "# Print the selected points\n",
    "print('The selected points on image 1 are:')\n",
    "print(points1)\n",
    "print('The selected points on image 2 are:')\n",
    "print(points2)\n",
    "\n",
    "# Find the homography matrix that maps the points from image 1 to image 2\n",
    "H, _ = cv2.findHomography(points1, points2)\n",
    "\n",
    "# Apply the homography matrix to warp image 1 to align with image 2\n",
    "im1_aligned = cv2.warpPerspective(im1, H, (im2.shape[1], im2.shape[0]))\n",
    "\n",
    "# Display the aligned image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(im1_aligned, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Aligned Image')\n",
    "plt.show()\n",
    "\n",
    "# Compute the mean squared error (MSE) between the aligned image and image 2\n",
    "mse = np.mean((im1_aligned - im2) ** 2)\n",
    "print(f'The mean squared error between the aligned image and image 2 is: {mse:.4f}')\n",
    "\n",
    "# Compute the structural similarity index measure (SSIM) between the aligned image and image 2\n",
    "ssim = cv2.compare_ssim(im1_aligned, im2, multichannel=True)\n",
    "print(f'The structural similarity index measure between the aligned image and image 2 is: {ssim:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
