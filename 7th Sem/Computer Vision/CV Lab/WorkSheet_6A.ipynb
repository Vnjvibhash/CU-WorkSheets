{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed520c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import os\n",
    "\n",
    "# # Function to load image dataset and corresponding labels\n",
    "# def load_dataset(data_dir):\n",
    "#     X = []\n",
    "#     y = []\n",
    "#     class_labels = os.listdir(data_dir)\n",
    "    \n",
    "#     for label, class_name in enumerate(class_labels):\n",
    "#         class_dir = os.path.join(data_dir, class_name)\n",
    "        \n",
    "#         for image_file in os.listdir(class_dir):\n",
    "#             image_path = os.path.join(class_dir, image_file)\n",
    "#             image = cv2.imread(image_path)\n",
    "#             X.append(image)\n",
    "#             y.append(label)\n",
    "    \n",
    "#     return np.array(X), np.array(y)\n",
    "\n",
    "# # Function to preprocess images (resize, normalize, convert to grayscale)\n",
    "# def preprocess_images(images, img_size, grayscale=True):\n",
    "#     processed_images = []\n",
    "    \n",
    "#     for image in images:\n",
    "#         if grayscale:\n",
    "#             image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#         if img_size is not None:\n",
    "#             image = cv2.resize(image, img_size)\n",
    "#         # You can add more preprocessing steps here (e.g., normalization)\n",
    "#         processed_images.append(image)\n",
    "    \n",
    "#     return np.array(processed_images)\n",
    "\n",
    "# # Function to extract local features from preprocessed images\n",
    "# def extract_local_features(images, feature_extractor):\n",
    "#     features = []\n",
    "    \n",
    "#     for image in images:\n",
    "#         kp, des = feature_extractor.detectAndCompute(image, None)\n",
    "#         if des is not None:\n",
    "#             features.append(des)\n",
    "    \n",
    "#     return np.vstack(features)\n",
    "\n",
    "# # Function to construct visual vocabulary using KMeans\n",
    "# def construct_visual_vocabulary(features, num_clusters):\n",
    "#     kmeans = KMeans(n_clusters=num_clusters)\n",
    "#     kmeans.fit(features)\n",
    "#     return kmeans\n",
    "\n",
    "# # Function to quantize local features based on visual vocabulary\n",
    "# def quantize_features(features, vocabulary):\n",
    "#     labels = vocabulary.predict(features)\n",
    "#     return labels\n",
    "\n",
    "# # Function to encode quantized features\n",
    "# def encode_features(labels, num_clusters):\n",
    "#     encoded_features = []\n",
    "#     for label in labels:\n",
    "#         histogram, _ = np.histogram(label, bins=range(num_clusters + 1))\n",
    "#         encoded_features.append(histogram)\n",
    "#     return np.array(encoded_features)\n",
    "\n",
    "# # Function to split dataset into training and testing sets\n",
    "# def split_dataset(X, y, test_size=0.2, random_state=42):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "#     return X_train, X_test, y_train, y_test\n",
    "\n",
    "# # Function to train classification model on training set using encoded features\n",
    "# def train_classification_model(X_train, y_train):\n",
    "#     clf = SVC()\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     return clf\n",
    "\n",
    "# # Function to evaluate trained model on testing set and calculate accuracy\n",
    "# def evaluate_model(model, X_test, y_test):\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     return accuracy\n",
    "\n",
    "# # Main function\n",
    "# def main():\n",
    "#     data_dir = 'data/test'\n",
    "#     img_size = (128, 128)  # Resize images to a common size (adjust as needed)\n",
    "#     num_clusters = 100  # Adjust as needed\n",
    "#     grayscale = True  # Set to True if you want to convert images to grayscale\n",
    "\n",
    "#     X, y = load_dataset(data_dir)\n",
    "#     X = preprocess_images(X, img_size, grayscale)\n",
    "#     feature_extractor = cv2.SIFT_create()\n",
    "#     features = extract_local_features(X, feature_extractor)\n",
    "#     vocabulary = construct_visual_vocabulary(features, num_clusters)\n",
    "#     labels = quantize_features(features, vocabulary)\n",
    "#     encoded_features = encode_features(labels, num_clusters)\n",
    "#     X_train, X_test, y_train, y_test = split_dataset(encoded_features, y)\n",
    "#     model = train_classification_model(X_train, y_train)\n",
    "#     accuracy = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "#     print(f'Accuracy with Bag of Features: {accuracy}')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n",
    "\n",
    "# # Analyze and interpret results\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "import os\n",
    "\n",
    "# Function to load image dataset and corresponding labels\n",
    "\n",
    "# def load_dataset(data_dir):\n",
    "#     X = []\n",
    "#     y = []\n",
    "#     class_labels = os.listdir(data_dir)\n",
    "    \n",
    "#     for label, class_name in enumerate(class_labels):\n",
    "#         class_dir = os.path.join(data_dir, class_name)\n",
    "        \n",
    "#         for image_file in os.listdir(class_dir):\n",
    "#             image_path = os.path.join(class_dir, image_file)\n",
    "#             image = cv2.imread(image_path)\n",
    "#             X.append(image)\n",
    "#             y.append(label)\n",
    "    \n",
    "#     return np.array(X), np.array(y)\n",
    "\n",
    "def load_dataset(dataset_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for subdir in os.listdir(dataset_path):\n",
    "        subdir_path = os.path.join(dataset_path, subdir)\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            image_path = os.path.join(subdir_path, filename)\n",
    "            # Load and preprocess the image (example using OpenCV) \n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(\"Failed to load the image.\")\n",
    "            else:\n",
    "                # Check if the image has valid dimensions\n",
    "                if not image.size == (0, 0):\n",
    "                    # Resize the image\n",
    "                    image = cv2.resize(image, (64, 64))\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Convert to grayscale\n",
    "                    # Append the image and label to the lists \n",
    "                    images.append(image)\n",
    "                    labels.append(subdir) # Assuming directory name represents the class label\n",
    "                else:\n",
    "                    print(\"The image has empty dimensions.\")\n",
    "    return images, labels\n",
    "\n",
    "# Function to preprocess images (resize, normalize, convert to grayscale)\n",
    "def preprocess_images(images, img_size, grayscale=True):\n",
    "    processed_images = []\n",
    "\n",
    "    for image in images:\n",
    "        if img_size is not None:\n",
    "            image = cv2.resize(image, img_size)\n",
    "\n",
    "        if grayscale:\n",
    "            if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                print(\"Warning: The image is not in BGR format; conversion to grayscale may not be necessary.\")\n",
    "        \n",
    "        processed_images.append(image)\n",
    "\n",
    "    return np.array(processed_images)\n",
    "\n",
    "# Function to extract local features from preprocessed images\n",
    "def extract_local_features(images, feature_extractor):\n",
    "    features = []\n",
    "    \n",
    "    for image in images:\n",
    "        kp, des = feature_extractor.detectAndCompute(image, None)\n",
    "        if des is not None and len(des) > 0:\n",
    "            features.append(des)\n",
    "    \n",
    "    if len(features) > 0:\n",
    "        return np.vstack(features)\n",
    "    else:\n",
    "        return None  # Return None if no features were extracted\n",
    "\n",
    "# Function to construct visual vocabulary using KMeans\n",
    "def construct_visual_vocabulary(features, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    kmeans.fit(features)\n",
    "    return kmeans\n",
    "\n",
    "# Function to quantize local features based on visual vocabulary\n",
    "def quantize_features(features, vocabulary):\n",
    "    labels = vocabulary.predict(features)\n",
    "    return labels\n",
    "\n",
    "# Function to encode quantized features\n",
    "def encode_features(labels, num_clusters):\n",
    "    encoded_features = []\n",
    "    for label in labels:\n",
    "        histogram, _ = np.histogram(label, bins=range(num_clusters + 1))\n",
    "        encoded_features.append(histogram)\n",
    "    return np.array(encoded_features)\n",
    "\n",
    "# Function to split dataset into training and testing sets\n",
    "def split_dataset(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Function to train classification model on training set using encoded features\n",
    "def train_classification_model(X_train, y_train):\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "# Function to evaluate trained model on testing set and calculate accuracy\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be318007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3f016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
